---
title: "Упражнение 5"
author: "Маркин Артем"
date: "27 03 2020"
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Постановка задачи: 

1. Оценить стандартную ошибку модели для линейных регрессионных моделей из упражнения 4 (варианты ниже): а) со всеми объясняющими переменными; б) только с непрерывными объясняющими переменными:  

- методом проверочной выборки с долей обучающей 50%;    
- методом LOOCV;    
- k-кратной кросс-валидацией с $k = 5$ и $k = 10$. 

Выбрать лучшую модель по минимуму ошибки. Все ли методы кросс-валидации сходятся на одной и той же модели?

2. Оценить стандартные ошибки параметров лучшей модели регрессии методом бутстрепа. Сравнить с оценками стандартных ошибок параметров по МНК.

## Вариант 12
 
*Данные*: `Carseats {ISLR}'.  

Набор данных `Carseats` содержит переменные:  

- `Sales` - Объем продаж (в тысячах) в каждом месте;
- `Price` – Ценовая компания взимает плату за автокресла на каждом сайте;
- `Population` – Численность населения в регионе (в тысячах);
- `US` – Коэффициент с уровнями Нет и Да, чтобы указать, находится ли магазин в США или нет.

```{r Данные и пакеты, warning = F, message = F}
# Пакеты
library('knitr')             # Генерация отчёта
library('ISLR')              # Набор данных Auto
library('GGally')            # Матричные графики
library('boot')              # Расчёт ошибки с кросс-валидацией

my.seed <- 1  # Константа для ядра

# Загрузка данных Auto
data('Carseats')
# Отбор необходимых данных для построения моделей
Carseats <- Carseats[,c('Sales', 'Price', 'Population', 'US'), drop = F]
```

Рассмотрим данные с характеристиками автомобилей `Carseats` из пакета `ISLR`. Скопируем таблицу во фрейм `DF.carseats` для дальнейших манипуляций.

```{r}
# Записываем данные во фрейм
DF.carseats <- Carseats

# Отобразим первые записи
head(DF.carseats)

# Описательные статистики
summary(DF.carseats)
```

В таблице данных `r nrow(DF.carseats)` наблюдений и `r ncol(DF.carseats)` переменных, среди которых есть непрерывные количественные и одна дискретная (`US`, Коэффициент с уровнями Нет и Да, чтобы указать, находится ли магазин в США или нет).
Построим графики разброса, показав фактор `US` цветом. Зависимой переменной модели будет `Sales`, её покажем в первой строке / столбце матричного графика.

```{r, cache = T, message = F, warning = F}
# Переведем переменную US в фактор
DF.carseats$US <- as.factor(DF.carseats$US)

# Графики разброса, цвет - количество цилиндров
ggpairs(DF.carseats, ggplot2::aes(color = US))
```

## Метод проверочной выборки 

Он состоит в том, что мы отбираем одну тестовую выборку и будем считать на ней ошибку модели.    

```{r}
# Общее число наблюдений
n <- nrow(DF.carseats)

# Доля обучающей выборки
train.percent <- 0.5

# Выбрать наблюдения в обучающую выборку
set.seed(my.seed)
inTrain <- sample(n, n * train.percent)

# Рисуем разными цветами обучающую и тестовую (для непрерывных переменных)

# Переменная Price
par(mfrow = c(1, 2))
plot(DF.carseats$Price[inTrain], DF.carseats$Sales[inTrain],
     xlab = 'Price', ylab = 'Sales', pch = 21,
     col = rgb(0, 0, 1, alpha = 0.4), bg = rgb(0, 0, 1, alpha = 0.4))
points(DF.carseats$Price[-inTrain], DF.carseats$Sales[-inTrain],
       pch = 21, col = rgb(1, 0, 0, alpha = 0.4), 
       bg = rgb(1, 0, 0, alpha = 0.4))
legend('topright', 
       pch = c(16, 16), col = c('blue', 'red'), legend = c('test', 'train'))

# Переменная Population
plot(DF.carseats$Population[inTrain], DF.carseats$Sales[inTrain],
     xlab = 'Population', ylab = 'Sales', pch = 21,
     col = rgb(0, 0, 1, alpha = 0.4), bg = rgb(0, 0, 1, alpha = 0.4))
points(DF.carseats$Population[-inTrain], DF.carseats$Sales[-inTrain],
       pch = 21, col = rgb(1, 0, 0, alpha = 0.4), 
       bg = rgb(1, 0, 0, alpha = 0.4))
legend('topright', 
       pch = c(16, 16), col = c('blue', 'red'), legend = c('test', 'train'))

par(mfrow = c(1, 1))
```

Построим модели для проверки точности. Вид моделей:

а) Со всеми объясняющими переменными
$$
\hat{Sales} = f(Price, Population, US);
$$

б) Только с непрерывными объясняющими переменными
$$
\hat{Sales} = f(Price, Population).
$$

**Линейная модель 1**: $\hat{Sales} = \hat{\beta}_0 + \hat{\beta}_1 \cdot Price + \hat{\beta}_2 \cdot Population + \hat{\beta}_3 \cdot US$.

``` {r, warning = F, message = F}
# Присоединить таблицу с данными: названия стоблцов будут доступны напрямую
attach(DF.carseats)

# Подгонка линейной модели на обучающей выборке
fit.lm.1 <- lm(Sales ~ Price + Population + US, subset = inTrain)

# Считаем MSE на тестовой выборке
mean((Sales[-inTrain] - predict(fit.lm.1, DF.carseats[-inTrain, ]))^2)

# Отсоединить таблицу с данными
detach(DF.carseats)
```

```{r}
# Сохраняем ошибку модели (MSE) на проверочной выборке
err.test <- mean((DF.carseats$Sales[-inTrain] - predict(fit.lm.1, 
                                                  DF.carseats[-inTrain, ]))^2)

# Сохранять все ошибки будем в один вектор, присваиваем имя первому элементу
#  (имя - степень объясняющей переменной)
names(err.test) <- 1
```

**Линейная модель 2**: $\hat{Sales} = \hat{\beta}_0 + \hat{\beta}_1 \cdot Price + \hat{\beta}_2 \cdot Population$

``` {r, warning = F, message = F}
# Присоединить таблицу с данными: названия стоблцов будут доступны напрямую
attach(DF.carseats)

# Подгонка линейной модели на обучающей выборке
fit.lm.2 <- lm(Sales ~ Price + Population, subset = inTrain)

# Считаем MSE на тестовой выборке
mean((Sales[-inTrain] - predict(fit.lm.2, DF.carseats[-inTrain, ]))^2)

# Отсоединить таблицу с данными
detach(DF.carseats)
```

```{r}
# Сохраняем ошибку модели (MSE) на проверочной выборке
err.test <- c(err.test,
              mean((DF.carseats$Sales[-inTrain] - predict(fit.lm.2,
                                                 DF.carseats[-inTrain, ]))^2))

# Имя второго элемента вектора
names(err.test)[length(err.test)] <- 2
```

## Перекрёстная проверка по отдельным наблюдениям (LOOCV)

Это самый затратный в вычислительном плане метод, но и самый надёжный в плане оценки ошибки вне выборки. Попробуем применить его к линейной модели 1.

```{r}
# Подгонка линейной модели на обучающей выборке
fit.glm1 <- glm(Sales ~ Price + Population + US, data = DF.carseats)

# Считаем LOOCV-ошибку
cv.err.loocv <- cv.glm(DF.carseats, fit.glm1)$delta[1]

# Сохранять все ошибки будем в один вектор, присваиваем имя первому элементу
#  (имя -- степень объясняющей переменной)
names(cv.err.loocv) <- 1
```  

Теперь оценим точность линейной модели 2.

```{r}
# Подгонка линейной модели на обучающей выборке
fit.glm2 <- glm(Sales ~ Price + Population, data = DF.carseats)

# Считаем LOOCV-ошибку
cv.err.loocv <- c(cv.err.loocv, cv.glm(DF.carseats, fit.glm2)$delta[1])

# Сохранять все ошибки будем в один вектор, присваиваем имя второму элементу
names(cv.err.loocv)[length(cv.err.loocv)] <- 2

# результат
cv.err.loocv
```  

### k-кратная перекрёстная проверка

K-кратная кросс-валидация - компромисс между методом проверочной выборки и LOOCV. Оценка ошибки вне выборки ближе к правде, по сравнению с проверочной выборкой, а объём вычислений меньше, чем при LOOCV. Проведём 5-кратную кросс-валидацию моделей 1 и 2. 

```{r}
# Оценим точность линейных моделей 1 и 2
# Вектор с ошибками по 5-кратной кросс-валидации
cv.err.k.fold5 <- rep(0, 2)

# Имена элементов вектора
names(cv.err.k.fold5) <- 1:2

# Оценка модели 1
fit.glm <- glm(Sales ~ Price + Population + US, data = DF.carseats)
# Расчёт ошибки
cv.err.k.fold5[1] <- cv.glm(DF.carseats, fit.glm, K = 5)$delta[1]

# Оценка модели 2
fit.glm <- glm(Sales ~ Price + Population, data = DF.carseats)
# Расчёт ошибки
cv.err.k.fold5[2] <- cv.glm(DF.carseats, fit.glm, K = 5)$delta[1]

# Результат
cv.err.k.fold5
```

Теперь проведём 10-кратную кросс-валидацию моделей 1 и 2.

```{r}
# Оценим точность линейных моделей 1 и 2
# Вектор с ошибками по 10-кратной кросс-валидации
cv.err.k.fold10 <- rep(0, 2)

# Имена элементов вектора
names(cv.err.k.fold10) <- 1:2

# Оценка модели 1
fit.glm <- glm(Sales ~ Price + Population + US, data = DF.carseats)
# Расчёт ошибки
cv.err.k.fold10[1] <- cv.glm(DF.carseats, fit.glm, K = 10)$delta[1]

# Оценка модели 2
fit.glm <- glm(Sales ~ Price + Population, data = DF.carseats)
# Расчёт ошибки
cv.err.k.fold10[2] <- cv.glm(DF.carseats, fit.glm, K = 10)$delta[1]

# Результат
cv.err.k.fold10
```

Для определения лучшей модели по стандартной ошибке MSE объединим все полученные результаты в таблицу.

```{r tbl}
MSE.tbl <- rbind(err.test, cv.err.loocv, cv.err.k.fold5, cv.err.k.fold10)
colnames(MSE.tbl) <- c('Модель 1', 'Модель 2')
row.names(MSE.tbl) <- c('Проверочная выборка', 'LOOCV', '5-кратная кросс-валидация', '10-кратная кросс-валидация')
kable(MSE.tbl)
```

Опираясь на результаты расчётов с проверочной выборкой, LOOCV и кросс-валидацией ($k = 5$ и $k = 10$), можно заключить, что стандартная ошибка MSE линейной модели 1 (со всеми объясняющими переменными) оказалась меньше по всем методам кросс-валидации, чем MSE линейной модели 2 (только с непрерывными объясняющими переменными). Таким образом, линейную модель 1 можно считать лучшей: $\hat{Sales} = \hat{\beta}_0 + \hat{\beta}_1 \cdot Price + \hat{\beta}_2 \cdot Population + \hat{\beta}_3 \cdot US$.

## Бутстреп   

### Точность оценки параметра регрессии   

При построении модели регрессии проблемы в остатках приводят к неверной оценке ошибок параметров. Обойти эту проблему можно, применив для расчёта этих ошибок бутстреп.

```{r, warning = F, message = F}
# Оценивание точности лучшей линейной регрессионной модели

# Оценить стандартные ошибки параметров модели 
# mpg = beta_0 + beta_1 * Price + beta_2 * Population + beta_3 * US с помощью бутстрепа,
# Сравнить с оценками ошибок по МНК

# функция для расчёта коэффициентов ЛР по выборке из данных
boot.fn <- function(data, index){
  coef(lm(Sales ~ Price + Population + US, data = data, subset = index))
}
boot.fn(DF.carseats, 1:n)

# Пример применения функции к бутстреп-выборке
set.seed(my.seed)
boot.fn(DF.carseats, sample(n, n, replace = T))

# Применяем функцию boot для вычисления стандартных ошибок параметров
#  (1000 выборок с повторами)
boot(DF.carseats, boot.fn, 1000)

# Сравним с МНК
attach(DF.carseats)
summary(lm(Sales ~ Price + Population + US))$coef
detach(DF.carseats)
```

В модели регрессии, для которой проводился расчёт, похоже, не нарушаются требования к остаткам, и оценки стандартных ошибок параметров, рассчитанные по МНК, очень близки к ошибкам этих же параметров, полученных бутстрепом.  